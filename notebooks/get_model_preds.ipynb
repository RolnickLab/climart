{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import h5py\n",
    "import json\n",
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict\n",
    "import rtml.data_wrangling.constants as constants\n",
    "from rtml.models.interface import get_model, is_gnn, is_graph_net, get_trainer\n",
    "from rtml.models.column_handler import ColumnPreprocesser\n",
    "from rtml.data_wrangling.constants import LEVELS, LAYERS, GLOBALS, OUTPUT, TRAIN_YEARS\n",
    "from rtml.data_wrangling.h5_dataset import RT_HdF5_Dataset\n",
    "from rtml.utils.utils import set_seed, get_name, year_string_to_list, identity\n",
    "from rtml.data_wrangling.constants import TEST_YEARS, LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 8]  # general matplotlib parameters\n",
    "plt.rcParams['figure.dpi'] = 70 \n",
    "np.set_printoptions(suppress=True, threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_years_dir = \"/miniscratch/salva.ruhling-cachay/ECC_data/snapshots/1979-2014/hdf5/inputs\"\n",
    "model_dir = \"scripts/out\"\n",
    "year = 2011\n",
    "h5_path = os.path.join(hdf5_years_dir, str(year) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_lon(data: np.ndarray = None):\n",
    "    coords_data = xr.open_dataset(\n",
    "        '/miniscratch/venkatesh.ramesh/ECC_data/snapshots/coords_data/areacella_fx_CanESM5_amip_r1i1p1f1_gn.nc'\n",
    "    )\n",
    "    lat = list(coords_data.get_index('lat'))\n",
    "    lon = list(coords_data.get_index('lon'))\n",
    "\n",
    "    latitude = []\n",
    "    longitude = []\n",
    "    for i in lat:\n",
    "        for j in lon:\n",
    "            latitude.append(i)\n",
    "            longitude.append(j)\n",
    "    lat_var = np.array(latitude)\n",
    "    lon_var = np.array(longitude)\n",
    "    return {'latitude': lat, 'longitude': lon, 'latitude_flattened': lat_var, 'longitude_flattened': lon_var}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### On GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(ckpt: str, year:str, device='cuda'):\n",
    "    \"\"\" init_batches are run but not accounted for in the benchmark, i.e. warm-up runs. \"\"\"\n",
    "    model_ckpt = torch.load(f\"{model_dir}/{ckpt}.pkl\", map_location=torch.device(device))\n",
    "    params = model_ckpt['hyper_params']\n",
    "    net_params = model_ckpt['model_params']\n",
    "    model_type = params['model']\n",
    "    \n",
    "    dataset_kwargs = dict(\n",
    "        exp_type=params['exp_type'],\n",
    "        target_type=params['target_type'],\n",
    "        target_variable=params['target_variable'],\n",
    "        input_transform=get_model(params['model'], only_class=True)._input_transform,\n",
    "        input_normalization=params['in_normalize'],\n",
    "        spatial_normalization_in=params['spatial_normalization_in'],\n",
    "        load_h5_into_mem=True\n",
    "    )\n",
    "    \n",
    "    dset = RT_HdF5_Dataset(years=year_string_to_list(str(year)), name='Eval', output_normalization=None, **dataset_kwargs)\n",
    "    dloader = torch.utils.data.DataLoader(dset, batch_size=512, pin_memory=True, shuffle=False, num_workers=2)\n",
    "    output_postprocesser = dset.output_variable_splitter\n",
    "\n",
    "    d = dset.h5_dsets[0].get_raw_input_data()\n",
    "    lvl_pressure = d[LEVELS][..., 2]\n",
    "    lay_pressure = d[LAYERS][..., 2]\n",
    "    cszrow = d[GLOBALS][..., 0]\n",
    "    print(cszrow.shape, lvl_pressure.shape, lay_pressure.shape)\n",
    "    \n",
    "    trainer_kwargs = dict(\n",
    "        model_name=params['model'], model_params=net_params,\n",
    "        device=params['device'], seed=params['seed'],\n",
    "        model_dir=params['model_dir'],\n",
    "        output_postprocesser=output_postprocesser,\n",
    "    )\n",
    "    if is_gnn(params['model']) or is_graph_net(params['model']):\n",
    "        trainer_kwargs['column_preprocesser'] = ColumnPreprocesser(\n",
    "            n_layers=dset.spatial_dim[LAYERS], input_dims=dset.input_dim, **params['preprocessing_dict']\n",
    "        )\n",
    "        tranform_name = trainer_kwargs['column_preprocesser'].preprocessing_type\n",
    "        if tranform_name not in ['mlp', 'mlp_projection']:\n",
    "            transform = trainer_kwargs['column_preprocesser'].get_preprocesser()\n",
    "            dset.set_input_transform(transform)\n",
    "\n",
    "    print(net_params)\n",
    "    trainer = get_trainer(**trainer_kwargs)\n",
    "    trainer.reload_model(model_state_dict=model_ckpt['model'])\n",
    "    preds, Y, _ = trainer.evaluate(dloader, verbose=True)\n",
    "    \n",
    "    \n",
    "    dset.close()    \n",
    "    return {'preds': preds, 'targets': Y, 'pressure': lvl_pressure, 'layer_pressure': lay_pressure, 'cstrow': cszrow}\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_preds(preds, targets, exp='pristine', model=None, year=None, **kwargs):\n",
    "    lat_lon = get_lat_lon()\n",
    "    lat, lon = lat_lon['latitude'], lat_lon['longitude']\n",
    "    n_levels = 50\n",
    "    n_layers = 49\n",
    "    shape = ['snapshot', 'latitude', 'longitude', 'level']\n",
    "    shape_lay = ['snapshot', 'latitude', 'longitude', 'layer']\n",
    "    shape_glob = ['snapshot', 'latitude', 'longitude']\n",
    "        \n",
    "    data_vars = dict()\n",
    "    for k, v in preds.items():\n",
    "        data_vars[f\"{k}_preds\"] = (shape, v.reshape((-1, len(lat), len(lon), n_levels)))\n",
    "    for k, v in targets.items():\n",
    "        data_vars[f\"{k}_targets\"] = (shape, v.reshape((-1, len(lat), len(lon), n_levels)))\n",
    "            \n",
    "    data_vars[\"pressure\"] = (shape, kwargs['pressure'].reshape((-1, len(lat), len(lon), n_levels)))\n",
    "    data_vars[\"layer_pressure\"] = (shape_lay, kwargs['layer_pressure'].reshape((-1, len(lat), len(lon), n_layers)))\n",
    "    data_vars[\"cszrow\"] = (shape_glob, kwargs['cszrow'].reshape((-1, len(lat), len(lon))))\n",
    "        \n",
    "    xr_dset = xr.Dataset(\n",
    "        data_vars=data_vars,\n",
    "        coords=dict(\n",
    "            longitude=lon,\n",
    "            latitude=lat,\n",
    "            level=list(range(n_levels))[::-1],\n",
    "            layer=list(range(n_layers))[::-1],\n",
    "        ),\n",
    "        attrs=dict(description=\"ML emulated RT outputs.\"),\n",
    "    )\n",
    "    if model is not None and year is not None:\n",
    "        xr_dset.to_netcdf(f'~/RT-DL/example_{exp}_preds_{model}_{year}.nc')\n",
    "    else:\n",
    "        print(\"Not saving to NC!\")\n",
    "    return xr_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "year = 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_gn_ckpt = \"0.2706valMAE_141ep_GN+READOUT_1985-90+1998-2004train_2005val_Z_7seed_15h50m_on_Aug_22_27kn4tto\"\n",
    "p_gn = get_preds(best_gn_ckpt, year=year, device = 'cuda')\n",
    "save_preds(**p_gn, model='graph_net', year=year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtml-gn",
   "language": "python",
   "name": "rtml-gn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}